{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e852f30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import Dataset,load_dataset,dataset_dict\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f7026bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "path =Path(\"D:\\workspace\\kaggle\\data\\\\feedback-prize-effectiveness\")\n",
    "train = path/\"train.csv\"\n",
    "data = pd.read_csv(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88c4d8e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>essay_id</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_effectiveness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013cc385424</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Adequate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9704a709b505</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>On my perspective, I think that the face is a ...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Adequate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c22adee811b6</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>I think that the face is a natural landform be...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Adequate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a10d361e54e4</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>If life was on Mars, we would know by now. The...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Adequate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>db3e453ec4e2</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>People thought that the face was formed by ali...</td>\n",
       "      <td>Counterclaim</td>\n",
       "      <td>Adequate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   discourse_id      essay_id  \\\n",
       "0  0013cc385424  007ACE74B050   \n",
       "1  9704a709b505  007ACE74B050   \n",
       "2  c22adee811b6  007ACE74B050   \n",
       "3  a10d361e54e4  007ACE74B050   \n",
       "4  db3e453ec4e2  007ACE74B050   \n",
       "\n",
       "                                      discourse_text discourse_type  \\\n",
       "0  Hi, i'm Isaac, i'm going to be writing about h...           Lead   \n",
       "1  On my perspective, I think that the face is a ...       Position   \n",
       "2  I think that the face is a natural landform be...          Claim   \n",
       "3  If life was on Mars, we would know by now. The...       Evidence   \n",
       "4  People thought that the face was formed by ali...   Counterclaim   \n",
       "\n",
       "  discourse_effectiveness  \n",
       "0                Adequate  \n",
       "1                Adequate  \n",
       "2                Adequate  \n",
       "3                Adequate  \n",
       "4                Adequate  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8216b238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi, i'm Isaac, i'm going to be writing about how this face on Mars is a natural landform or if there is life on Mars that made it. The story is about how NASA took a picture of Mars and a face was seen on the planet. NASA doesn't know if the landform was created by life on Mars, or if it is just a natural landform. \""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[0].discourse_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "139f6aaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"On my perspective, I think that the face is a natural landform because I dont think that there is any life on Mars. In these next few paragraphs, I'll be talking about how I think that is is a natural landform \""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[1].discourse_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc6a0adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"label\"] = data.discourse_effectiveness.astype(\"category\").cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f760edd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43999983e8004f3b9d89ce7d077b0960",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6130b386f9f4801a589b0b94d9fd75b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/578 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ec0c206801c4116823dff9060ee1bdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.35M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "D:\\Anaconda3\\lib\\site-packages\\transformers\\convert_slow_tokenizer.py:434: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c58a13cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"inputs\"] = data.discourse_type+tokenizer.sep_token+data.discourse_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c50204ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>essay_id</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_effectiveness</th>\n",
       "      <th>label</th>\n",
       "      <th>inputs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013cc385424</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>0</td>\n",
       "      <td>Lead[SEP]Hi, i'm Isaac, i'm going to be writin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9704a709b505</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>On my perspective, I think that the face is a ...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>0</td>\n",
       "      <td>Position[SEP]On my perspective, I think that t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c22adee811b6</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>I think that the face is a natural landform be...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>0</td>\n",
       "      <td>Claim[SEP]I think that the face is a natural l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a10d361e54e4</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>If life was on Mars, we would know by now. The...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>0</td>\n",
       "      <td>Evidence[SEP]If life was on Mars, we would kno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>db3e453ec4e2</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>People thought that the face was formed by ali...</td>\n",
       "      <td>Counterclaim</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>0</td>\n",
       "      <td>Counterclaim[SEP]People thought that the face ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   discourse_id      essay_id  \\\n",
       "0  0013cc385424  007ACE74B050   \n",
       "1  9704a709b505  007ACE74B050   \n",
       "2  c22adee811b6  007ACE74B050   \n",
       "3  a10d361e54e4  007ACE74B050   \n",
       "4  db3e453ec4e2  007ACE74B050   \n",
       "\n",
       "                                      discourse_text discourse_type  \\\n",
       "0  Hi, i'm Isaac, i'm going to be writing about h...           Lead   \n",
       "1  On my perspective, I think that the face is a ...       Position   \n",
       "2  I think that the face is a natural landform be...          Claim   \n",
       "3  If life was on Mars, we would know by now. The...       Evidence   \n",
       "4  People thought that the face was formed by ali...   Counterclaim   \n",
       "\n",
       "  discourse_effectiveness  label  \\\n",
       "0                Adequate      0   \n",
       "1                Adequate      0   \n",
       "2                Adequate      0   \n",
       "3                Adequate      0   \n",
       "4                Adequate      0   \n",
       "\n",
       "                                              inputs  \n",
       "0  Lead[SEP]Hi, i'm Isaac, i'm going to be writin...  \n",
       "1  Position[SEP]On my perspective, I think that t...  \n",
       "2  Claim[SEP]I think that the face is a natural l...  \n",
       "3  Evidence[SEP]If life was on Mars, we would kno...  \n",
       "4  Counterclaim[SEP]People thought that the face ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "833e32f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "594952c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(source):\n",
    "    return tokenizer(source[\"inputs\"],truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b77c6d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bc7f621d061415ab5bd2203826beac2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(tokenize_function,batched=True,remove_columns = [\"discourse_id\",\\\n",
    "                                                                              \"essay_id\",\\\n",
    "                                                                             \"discourse_text\",\\\n",
    "                                                                              \"discourse_type\",\\\n",
    "                                                                             \"discourse_effectiveness\",\\\n",
    "                                                                             ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "788d9c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "essay_id = data.essay_id.unique()\n",
    "np.random.shuffle(essay_id)\n",
    "split = int(len(essay_id)*0.9)\n",
    "\n",
    "val_essay = essay_id[split:]\n",
    "val_id = np.isin(data[\"essay_id\"],val_essay)\n",
    "train_id = ~val_id\n",
    "idx = np.arange(data.shape[0])\n",
    "train_idx = idx[train_id]\n",
    "val_idx = idx[val_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0063e5da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     1,     2, ..., 36762, 36763, 36764])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0fdd9b8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  130,   131,   132, ..., 36727, 36728, 36729])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66ff35e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Dataset = tokenized_dataset.select(train_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8b8c85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_Dataset = tokenized_dataset.select(val_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "894fa34e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'inputs', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 33111\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5cbbdaef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1e99a1d40c04eac9e7c64bf4e634fd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/34 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f69fbfefa87d445cb5e4d588db3c5bff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_Dataset.save_to_disk(\"train\")\n",
    "val_Dataset.save_to_disk(\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73a6fe6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "dd = load_from_disk(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac316201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'inputs', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 33111\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661e11b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
